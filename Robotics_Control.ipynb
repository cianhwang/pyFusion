{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROBOTICS FOCUS CONTROL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions import Normal\n",
    "from torch.utils import data\n",
    "from torchvision import transforms, utils\n",
    "import pwc_5x5_sigmoid_bilinear    # cm:import AWnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameter_number(net):\n",
    "    '''\n",
    "    print total and trainable number of params \n",
    "    '''\n",
    "    total_num = sum(p.numel() for p in net.parameters())\n",
    "    trainable_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    return {'Total': total_num, 'Trainable': trainable_num}\n",
    "\n",
    "def dfs_freeze(model):\n",
    "    '''\n",
    "    freeze the network\n",
    "    '''\n",
    "    for name, child in model.named_children():\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "        dfs_freeze(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class focusLocNet(nn.Module):\n",
    "    '''\n",
    "    Description: analyze estimated ^J_{t-1} to get next focus position sampled from Gaussian distr.\n",
    "    \n",
    "    input: \n",
    "        x: (B, 3, 512, 896) image tensor\n",
    "            range [-1, 1]\n",
    "\n",
    "    output: \n",
    "        mu: (B, 1) mean of gaussian distribution\n",
    "            range [-1, 1]\n",
    "        pos: (B, 1) normalized focus position\n",
    "            range [-1, 1]\n",
    "        log_pi: logarithmatic probabilty of choosing pos ~ Gauss(mu, self.std)\n",
    "        \n",
    "    arguments:\n",
    "        std: std of gaussian distribution\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, std = 0.05):\n",
    "        super(focusLocNet, self).__init__()\n",
    "        \n",
    "        self.std = std\n",
    "        \n",
    "        self.block1 = convBlock(3, 16, 7, 2)\n",
    "        self.block2 = convBlock(16, 32, 5, 2)\n",
    "        self.block3 = convBlock(32, 64, 5, 2)\n",
    "        self.block4 = convBlock(64, 64, 5, 2)\n",
    "        self.block5 = convBlock(64, 128, 5, 2)        \n",
    "        self.block6 = convBlock(128, 128, 5, 4, isBn = False)\n",
    "        self.lstm = nn.LSTMCell(2304, 512)\n",
    "        self.fc1 = nn.Linear(2304, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 16)\n",
    "        self.fc4 = nn.Linear(16, 1)   \n",
    "        \n",
    "        self.lstm_hidden = self.init_hidden()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "\n",
    "        return (None, None)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x) \n",
    "        x = self.block3(x) \n",
    "        x = self.block4(x) \n",
    "        x = self.block5(x) \n",
    "        x = self.block6(x)\n",
    "        \n",
    "        x = x.view(x.size()[0], -1)\n",
    "        \n",
    "        if self.lstm_hidden is not (None, None):\n",
    "            self.lstm_hidden = self.lstm(x)\n",
    "        else:\n",
    "            self.lstm_hidden = self.lstm(x, self.lstm_hidden)\n",
    "\n",
    "#             self.h, self.c = self.lstm(x, (self.h, self.c))\n",
    "        x = F.relu(self.lstm_hidden[0])\n",
    "#         x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        mu = torch.tanh(self.fc4(x))\n",
    "        \n",
    "        noise = torch.zeros_like(mu)\n",
    "        noise.data.normal_(std=self.std)\n",
    "        pos = mu + noise\n",
    "\n",
    "        # bound between [-1, 1]\n",
    "        pos = torch.tanh(pos)\n",
    "        \n",
    "        log_pi = Normal(mu, self.std).log_prob(pos)\n",
    "        log_pi = torch.sum(log_pi, dim=1)\n",
    "        \n",
    "        return mu, pos, log_pi\n",
    "\n",
    "class convBlock(nn.Module):\n",
    "    '''\n",
    "    Conv+ReLU+BN\n",
    "    '''\n",
    "\n",
    "    def __init__(self, in_feature, out_feature, filter_size, stride = 1, activation = F.relu, isBn = True):\n",
    "        super(convBlock, self).__init__()\n",
    "        self.isBn = isBn\n",
    "        self.activation = activation\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_feature, out_feature, filter_size, stride=stride)\n",
    "        torch.nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        self.bn1 = nn.BatchNorm2d(out_feature)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)        \n",
    "            \n",
    "        if self.isBn:\n",
    "            x = self.bn1(x)\n",
    "        return x            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained AWnet\n",
    "AWnet = pwc_5x5_sigmoid_bilinear.pwc_residual().cuda()\n",
    "AWnet.load_state_dict(torch.load('fs0_61_294481_0.00919393_dict.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconsLoss(J_est, J_gt):   \n",
    "    '''\n",
    "    Calculate loss (neg reward) of Reinforcement learning\n",
    "    \n",
    "    input: \n",
    "        J_est: (B, Seq, C, H, W) predicted image sequences\n",
    "        J_gt: (B, Seq, C, H, W) ground truth image sequence\n",
    "\n",
    "    output: \n",
    "        lossTensor: (B, 1)\n",
    "            mse value for each sequence of images in minibatch.\n",
    "    '''\n",
    "    lossList = []\n",
    "\n",
    "    for i in range(J_gt.size()[0]):\n",
    "        lossList.append(F.mse_loss(J_gt, J_est))\n",
    "    \n",
    "    lossTensor = torch.stack(lossList)\n",
    "    return lossTensor\n",
    "   \n",
    "def getDefocuesImage(focusPos):\n",
    "    '''\n",
    "    Camera model. \n",
    "    Input: \n",
    "        focusPos Tensor(B, 1): current timestep focus position\n",
    "    Output: \n",
    "        imageTensor (B, C, H, W): current timestep captured minibatch\n",
    "    '''\n",
    "    imageTensor = torch.rand(focusPos.size()[0], 3, 512, 896).to(device) # ongoing\n",
    "    \n",
    "    return imageTensor\n",
    "\n",
    "def fuseTwoImages(I, J_hat):\n",
    "    '''\n",
    "    AWnet fusion algorithm. \n",
    "    Input:\n",
    "        I Tensor (B, C, H, W): current timestep captured minibatch\n",
    "        J Tensor (B, C, H, W): last timestep fused minibatch\n",
    "    Output:\n",
    "        fusedTensor (B, C, H, W): current timestep fused minibatch\n",
    "    '''\n",
    "    fuseTensor,warp,mask = AWnet(J_hat,I)\n",
    "    # fusedTensor = I+J_hat   #ongoing\n",
    "    return fusedTensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "focusLocNet(\n",
      "  (block1): convBlock(\n",
      "    (conv1): Conv2d(3, 16, kernel_size=(7, 7), stride=(2, 2))\n",
      "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (block2): convBlock(\n",
      "    (conv1): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2))\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (block3): convBlock(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2))\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (block4): convBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2))\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (block5): convBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2))\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (block6): convBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(5, 5), stride=(4, 4))\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (lstm): LSTMCell(2304, 512)\n",
      "  (fc1): Linear(in_features=2304, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=16, bias=True)\n",
      "  (fc4): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Total': 7803617, 'Trainable': 7803617}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = focusLocNet().to(device)\n",
    "print(model)\n",
    "get_parameter_number(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# pseudo data test\n",
    "# '''\n",
    "# x = torch.rand(1, 3, 512, 896)\n",
    "# mu, l, p = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, gross, transform = None):\n",
    "        self.gross = gross\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.gross\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        X = torch.rand(5, 3, 512, 896)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "'''\n",
    "Generate pseudo data for training.\n",
    "'''    \n",
    "\n",
    "dataset = Dataset(21, transform = transforms.Compose([\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "params = {'batch_size':7, 'shuffle':True, 'num_workers':4}\n",
    "dataGenerator = data.DataLoader(dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataGenerator, optimizer):\n",
    "    \n",
    "    for i, y_train in enumerate(dataGenerator):\n",
    "\n",
    "        y_train = y_train.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # data shape: y_train (B, Seq, C, H, W)\n",
    "        log_pi = []\n",
    "        J_est = []\n",
    "        J_prev = y_train[:, 0, ...] ## set J_prev to be first frame of the image sequences\n",
    "        J_est.append(J_prev)\n",
    "        \n",
    "        for t in range(y_train.size()[1]-1):\n",
    "            # for each time step: estimate, capture and fuse.\n",
    "            mu, l, p = model(J_prev)\n",
    "            log_pi.append(p)\n",
    "            I = getDefocuesImage(l)\n",
    "            J_prev = fuseTwoImages(I, J_prev)\n",
    "            J_est.append(J_prev)\n",
    "            \n",
    "        J_est = torch.stack(J_est, dim = 1)\n",
    "        \n",
    "        log_pi = torch.stack(log_pi).transpose(1, 0)\n",
    "        R = -reconsLoss(J_est, y_train)\n",
    "        R = R.unsqueeze(1).repeat(1, y_train.size()[1]-1)\n",
    "        \n",
    "        ## Basic REINFORCE algorithm\n",
    "        loss = torch.sum(-log_pi*R, dim=1)\n",
    "        loss = torch.mean(loss, dim=0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.init_hidden()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_epoch(dataGenerator, optim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
